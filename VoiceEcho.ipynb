{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca81e777-5940-4082-83e8-cef86decb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup stuff goes here\n",
    "import utils\n",
    "\n",
    "utils.setupOpenAIAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a62821-64dc-4e0b-9778-107ca340867a",
   "metadata": {},
   "source": [
    "# Text to Audo (TTA) Demostration\n",
    "\n",
    "Converts text to a mp3 file with OpenAI's TTA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467d0a4-5803-4a37-b55c-9803af55e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFileOutput = \"audio_ouput.mp3\"\n",
    "text = \"Hello World! Hear me speak!\"\n",
    "\n",
    "utils.textToAudioFile(text, audioFileOutput) # Convert example text to audio file as test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08edb0-5750-4043-bb32-19e056529e53",
   "metadata": {},
   "source": [
    "# Audio to Text (ATT) Demostration\n",
    "\n",
    "Converts Audio file to text(ATT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf026a0-1987-4a67-a27b-35d10fee41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFileInput = \"Audio Input Test.m4a\" \n",
    "\n",
    "transcription = utils.audioToText(audioFileInput)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad71d6-9a26-4dfa-adf6-7c91836f3501",
   "metadata": {},
   "source": [
    "# First Echo Attempt\n",
    "Successfully detects human voice, starts recording when human speaks, stops recording when human speaks and then converts human speech to text and then text to audio and plays back audio the human spoke in OpenAI's TTA voice.\n",
    "\n",
    "Not real time or useful in practical as only when finish recording does it translate to text and text to audio and only when audio is finished writting to file does it play back. this means that it is so slow and this is the subject of the next improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639dc704-15e9-413a-b83b-eda6e51323eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Speak now.\n",
      "Recording started.\n",
      "Recording stopped.\n",
      "Recording complete.\n",
      "Transcription: This is the test.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import collections\n",
    "import time\n",
    "\n",
    "# Define audio parameters\n",
    "fs = 16000 \n",
    "frame_duration_ms = 30 \n",
    "\n",
    "def record_audio_vad(filename):\n",
    "    vad = webrtcvad.Vad(1)\n",
    "    num_padding_frames = 10 \n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    triggered = False\n",
    "    voiced_frames = []\n",
    "    print(\"Recording... Speak now.\")\n",
    "\n",
    "    silence_threshold_seconds = 1.5 \n",
    "    last_voice_timestamp = time.time()\n",
    "\n",
    "    with sd.InputStream(samplerate=fs, channels=1, dtype='int16') as stream:\n",
    "        while True:\n",
    "            audio_chunk, overflowed = stream.read(int(fs * frame_duration_ms / 1000))\n",
    "            is_speech = vad.is_speech(audio_chunk.tobytes(), fs)\n",
    "\n",
    "            if is_speech:\n",
    "                last_voice_timestamp = time.time()\n",
    "\n",
    "            if not triggered:\n",
    "                ring_buffer.append((audio_chunk, is_speech))\n",
    "                num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "                if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    print(\"Recording started.\")\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(audio_chunk)\n",
    "                ring_buffer.append((audio_chunk, is_speech))\n",
    "                num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "                \n",
    "                if num_unvoiced > 0.9 * (ring_buffer.maxlen) and (time.time() - last_voice_timestamp > silence_threshold_seconds):\n",
    "                    print(\"Recording stopped.\")\n",
    "                    break\n",
    "\n",
    "    audio_data = np.concatenate(voiced_frames, axis=0)\n",
    "    wav.write(filename, fs, audio_data)\n",
    "    print(\"Recording complete.\")\n",
    "\n",
    "def transcribe_audio(filename):\n",
    "    return utils.audioToText(filename) \n",
    "\n",
    "def synthesize_speech(text, output_filename):\n",
    "    utils.textToAudioFile(text, output_filename) \n",
    "\n",
    "def play_audio(filename):\n",
    "    audio = AudioSegment.from_mp3(filename)\n",
    "    play(audio)\n",
    "\n",
    "input_audio_file = \"input5.wav\"\n",
    "output_audio_file = \"output5.mp3\"\n",
    "\n",
    "record_audio_vad(input_audio_file)\n",
    "transcription = transcribe_audio(input_audio_file)\n",
    "print(\"Transcription:\", transcription)\n",
    "\n",
    "synthesize_speech(transcription, output_audio_file)\n",
    "play_audio(output_audio_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9599d2-c4e4-421d-aa35-ec76ba2a3b71",
   "metadata": {},
   "source": [
    "# Second Echo Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7b31d-58da-4422-a113-bb754eb06e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ursusprizlius/.pyenv/versions/3.9.6/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/ursusprizlius/Documents/Projects/audio-to-text-client/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/ursusprizlius/.pyenv/versions/3.9.6/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/qn/g265ll392sz062bdvw23pz680000gn/T/ipykernel_15697/1540040607.py\", line 28, in record_audio_chunks\n",
      "NameError: name 'audio_chunk' is not defined\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import collections\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import io  # For in-memory audio handling\n",
    "\n",
    "\n",
    "fs = 16000\n",
    "frame_duration_ms = 250  # Smaller chunk size\n",
    "audio_queue = queue.Queue()\n",
    "transcription_queue = queue.Queue()\n",
    "speech_queue = queue.Queue()\n",
    "\n",
    "# --- VAD and Audio Chunking ---\n",
    "def record_audio_chunks():\n",
    "    vad = webrtcvad.Vad(1) \n",
    "    # ... (Adjust VAD parameters for responsiveness) \n",
    "    with sd.InputStream(samplerate=fs, channels=1, dtype='int16') as stream:\n",
    "        while True:\n",
    "            # ... (Record audio chunk)\n",
    "            audio_queue.put(audio_chunk)\n",
    "\n",
    "# --- Asynchronous Transcription ---\n",
    "def transcribe_worker():\n",
    "    while True:\n",
    "        audio_chunk = audio_queue.get()\n",
    "        # ... (Convert audio_chunk to bytes-like object) \n",
    "        with io.BytesIO() as audio_buffer:\n",
    "            wav.write(audio_buffer, fs, audio_chunk)\n",
    "            audio_buffer.seek(0) \n",
    "            transcription = utils.audioToText(audio_buffer) \n",
    "        transcription_queue.put(transcription)\n",
    "        audio_queue.task_done()\n",
    "\n",
    "# --- Asynchronous Speech Synthesis ---\n",
    "def synthesize_worker():\n",
    "    while True:\n",
    "        text = transcription_queue.get()\n",
    "        with io.BytesIO() as speech_buffer:\n",
    "            utils.textToAudioFile(text, speech_buffer)\n",
    "            speech_buffer.seek(0)\n",
    "            speech_data = speech_buffer.read()\n",
    "        speech_queue.put(speech_data)\n",
    "        transcription_queue.task_done()\n",
    "\n",
    "# --- Audio Playback --- \n",
    "def play_audio_worker():\n",
    "    while True:\n",
    "        speech_data = speech_queue.get()\n",
    "        audio = AudioSegment.from_mp3(io.BytesIO(speech_data)) \n",
    "        play(audio)\n",
    "        speech_queue.task_done() \n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ... (Set up your OpenAI API client)\n",
    "\n",
    "    # Start worker threads\n",
    "    threading.Thread(target=record_audio_chunks, daemon=True).start()\n",
    "    threading.Thread(target=transcribe_worker, daemon=True).start()\n",
    "    threading.Thread(target=synthesize_worker, daemon=True).start()\n",
    "    threading.Thread(target=play_audio_worker, daemon=True).start()\n",
    "\n",
    "    # Keep the main thread alive\n",
    "    while True:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbfae95-d954-4f5d-930b-73a6bfa7e9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FirstAIProject Env",
   "language": "python",
   "name": "my-jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
