{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca81e777-5940-4082-83e8-cef86decb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup stuff goes here\n",
    "import utils\n",
    "\n",
    "utils.setupOpenAIAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a62821-64dc-4e0b-9778-107ca340867a",
   "metadata": {},
   "source": [
    "# Text to Audo (TTA) Demostration\n",
    "\n",
    "Converts text to a mp3 file with OpenAI's TTA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467d0a4-5803-4a37-b55c-9803af55e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFileOutput = \"audio_ouput.mp3\"\n",
    "text = \"Hello World! Hear me speak!\"\n",
    "\n",
    "utils.textToAudioFile(text, audioFileOutput) # Convert example text to audio file as test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08edb0-5750-4043-bb32-19e056529e53",
   "metadata": {},
   "source": [
    "# Audio to Text (ATT) Demostration\n",
    "\n",
    "Converts Audio file to text(ATT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf026a0-1987-4a67-a27b-35d10fee41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFileInput = \"Audio Input Test.m4a\" \n",
    "\n",
    "transcription = utils.audioToText(audioFileInput)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad71d6-9a26-4dfa-adf6-7c91836f3501",
   "metadata": {},
   "source": [
    "# First Echo Attempt\n",
    "Successfully detects human voice, starts recording when human speaks, stops recording when human speaks and then converts human speech to text and then text to audio and plays back audio the human spoke in OpenAI's TTA voice.\n",
    "\n",
    "Not real time or useful in practical as only when finish recording does it translate to text and text to audio and only when audio is finished writting to file does it play back. this means that it is so slow and this is the subject of the next improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639dc704-15e9-413a-b83b-eda6e51323eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Speak now.\n",
      "Recording started.\n",
      "Recording stopped.\n",
      "Recording complete.\n",
      "Transcription: Hello.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import collections\n",
    "import time\n",
    "\n",
    "# Define audio parameters\n",
    "fs = 16000 \n",
    "frame_duration_ms = 30 \n",
    "\n",
    "def record_audio_vad(filename):\n",
    "    vad = webrtcvad.Vad(1)\n",
    "    num_padding_frames = 10 \n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    triggered = False\n",
    "    voiced_frames = []\n",
    "    print(\"Recording... Speak now.\")\n",
    "\n",
    "    # silence_threshold_seconds = 1.5 \n",
    "    silence_threshold_seconds = 0 \n",
    "    last_voice_timestamp = time.time()\n",
    "\n",
    "    with sd.InputStream(samplerate=fs, channels=1, dtype='int16') as stream:\n",
    "        while True:\n",
    "            audio_chunk, overflowed = stream.read(int(fs * frame_duration_ms / 1000))\n",
    "            is_speech = vad.is_speech(audio_chunk.tobytes(), fs)\n",
    "\n",
    "            if is_speech:\n",
    "                last_voice_timestamp = time.time()\n",
    "\n",
    "            if not triggered:\n",
    "                ring_buffer.append((audio_chunk, is_speech))\n",
    "                num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "                if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    print(\"Recording started.\")\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(audio_chunk)\n",
    "                ring_buffer.append((audio_chunk, is_speech))\n",
    "                num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "                \n",
    "                if num_unvoiced > 0.9 * (ring_buffer.maxlen) and (time.time() - last_voice_timestamp > silence_threshold_seconds):\n",
    "                    print(\"Recording stopped.\")\n",
    "                    break\n",
    "\n",
    "    audio_data = np.concatenate(voiced_frames, axis=0)\n",
    "    wav.write(filename, fs, audio_data)\n",
    "    print(\"Recording complete.\")\n",
    "\n",
    "def transcribe_audio(filename):\n",
    "    return utils.audioToText(filename) \n",
    "\n",
    "def synthesize_speech(text, output_filename):\n",
    "    utils.textToAudioFile(text, output_filename) \n",
    "\n",
    "def play_audio(filename):\n",
    "    audio = AudioSegment.from_mp3(filename)\n",
    "    play(audio)\n",
    "\n",
    "input_audio_file = \"input6.wav\"\n",
    "output_audio_file = \"output6.mp3\"\n",
    "\n",
    "record_audio_vad(input_audio_file)\n",
    "transcription = transcribe_audio(input_audio_file)\n",
    "print(\"Transcription:\", transcription)\n",
    "\n",
    "synthesize_speech(transcription, output_audio_file)\n",
    "play_audio(output_audio_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9599d2-c4e4-421d-aa35-ec76ba2a3b71",
   "metadata": {},
   "source": [
    "# Second Echo Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014cf962-2506-41dd-9089-33b3fabac358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: how old is the Brooklyn Bridge\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech_v1 as speech\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "def run_quickstart() -> speech.RecognizeResponse:\n",
    "    \"\"\"Runs the Speech-to-Text quickstart with credentials.\"\"\"\n",
    "\n",
    "    # **Move credentials definition outside the function**\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "    'google_credential.json')\n",
    "    # credentials = cr.from_service_account_file(\"google_credential.json\")\n",
    "\n",
    "    # Create a Speech client with credentials\n",
    "    client = speech.SpeechClient(credentials=credentials)\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    gcs_uri = \"gs://cloud-samples-data/speech/brooklyn_bridge.raw\"  # Replace with your audio file URI (e.g., local path)\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",  # Change to your desired language code\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_quickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e918665-f5f1-4728-853a-ca2042b9a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening (press Ctrl+C to stop)...\n",
      "Transcript: Now it's dinner time.\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import sys\n",
    "import sounddevice as sd\n",
    "from google.cloud import speech_v1 as speech\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "# CHUNK = int(RATE / 10)  # 100ms\n",
    "CHUNK = int(RATE)  # 100ms\n",
    "\n",
    "# Initialize the queue to hold audio data\n",
    "q = queue.Queue()\n",
    "\n",
    "# Define the callback function to process audio data\n",
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    q.put(bytes(indata))\n",
    "\n",
    "def main():\n",
    "    credentials = service_account.Credentials.from_service_account_file('google_credential.json')\n",
    "\n",
    "    client = speech.SpeechClient(credentials=credentials)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=\"en-US\",\n",
    "        enable_automatic_punctuation=True\n",
    "    )\n",
    "    # streaming_config = speech.StreamingRecognitionConfig(config=config, interim_results=True)\n",
    "    streaming_config = speech.StreamingRecognitionConfig(config=config, interim_results=False)\n",
    "\n",
    "    def generator():\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if data is None:\n",
    "                break\n",
    "            yield speech.StreamingRecognizeRequest(audio_content=data)\n",
    "\n",
    "    with sd.RawInputStream(samplerate=RATE, blocksize=CHUNK, dtype='int16',\n",
    "                           channels=1, callback=callback):\n",
    "        print(\"Listening (press Ctrl+C to stop)...\")\n",
    "        requests = generator()\n",
    "        responses = client.streaming_recognize(config=streaming_config, requests=requests)\n",
    "\n",
    "        try:\n",
    "            for response in responses:\n",
    "                for result in response.results:\n",
    "                    if result.is_final:\n",
    "                        print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "                    else:\n",
    "                        print(f\"Intermediate transcript: {result.alternatives[0].transcript}\", end='\\r')\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nExiting...\")\n",
    "            q.put(None)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3618ba-a5f9-47b6-8838-f0f19548af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import texttospeech\n",
    "from google.oauth2 import service_account\n",
    "from pydub import AudioSegment\n",
    "import simpleaudio as sa\n",
    "\n",
    "def text_to_speech(text):\n",
    "    # Define the credentials file\n",
    "    credentials = service_account.Credentials.from_service_account_file('google_credential.json')\n",
    "\n",
    "    # Initialize the Text-to-Speech client\n",
    "    client = texttospeech.TextToSpeechClient(credentials=credentials)\n",
    "\n",
    "    # Set the text input to be synthesized\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "    # Build the voice request\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "    )\n",
    "\n",
    "    # Select the type of audio file you want returned\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    # Perform the text-to-speech request\n",
    "    response = client.synthesize_speech(\n",
    "        input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    # Use pydub to load the audio content\n",
    "    audio = AudioSegment.from_file(io.BytesIO(response.audio_content), format=\"mp3\")\n",
    "\n",
    "    # Play the audio using simpleaudio\n",
    "    play_obj = sa.play_buffer(\n",
    "        audio.raw_data,\n",
    "        num_channels=audio.channels,\n",
    "        bytes_per_sample=audio.sample_width,\n",
    "        sample_rate=audio.frame_rate\n",
    "    )\n",
    "\n",
    "    # Wait for playback to finish before exiting\n",
    "    play_obj.wait_done()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"Hello, world! This is a text-to-speech test using Google Cloud.\"\n",
    "    text_to_speech(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8fe44-1594-4d03-a8be-1cf4f6a498fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import texttospeech\n",
    "from google.oauth2 import service_account\n",
    "from pydub import AudioSegment\n",
    "import simpleaudio as sa\n",
    "\n",
    "def text_to_speech(text):\n",
    "    # Define the credentials file\n",
    "    credentials = service_account.Credentials.from_service_account_file('google_credential.json')\n",
    "\n",
    "    # Initialize the Text-to-Speech client\n",
    "    client = texttospeech.TextToSpeechClient(credentials=credentials)\n",
    "\n",
    "    # Set the text input to be synthesized\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "    # Build the voice request\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "    )\n",
    "\n",
    "    # Select the type of audio file you want returned\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    # Perform the text-to-speech request\n",
    "    response = client.synthesize_speech(\n",
    "        input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    # Use pydub to load the audio content\n",
    "    audio = AudioSegment.from_file(io.BytesIO(response.audio_content), format=\"mp3\")\n",
    "\n",
    "    # Play the audio using simpleaudio\n",
    "    play_obj = sa.play_buffer(\n",
    "        audio.raw_data,\n",
    "        num_channels=audio.channels,\n",
    "        bytes_per_sample=audio.sample_width,\n",
    "        sample_rate=audio.frame_rate\n",
    "    )\n",
    "\n",
    "    # Wait for playback to finish before exiting\n",
    "    play_obj.wait_done()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"Dinosaurs exist everywhere in the world!\"\n",
    "    text_to_speech(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e478e0-da8c-4622-998f-908bbda90017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latency:6.948406934738159 seconds\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from google.cloud import texttospeech\n",
    "from google.oauth2 import service_account\n",
    "from pydub import AudioSegment\n",
    "import pyaudio\n",
    "import time\n",
    "\n",
    "def play_audio(audio_segment):\n",
    "    # Initialize PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open a .Stream with the appropriate settings\n",
    "    stream = p.open(format=p.get_format_from_width(audio_segment.sample_width),\n",
    "                    channels=audio_segment.channels,\n",
    "                    rate=audio_segment.frame_rate,\n",
    "                    output=True)\n",
    "\n",
    "    # Write the raw audio data to the stream\n",
    "    stream.write(audio_segment.raw_data)\n",
    "\n",
    "    # Close the stream and terminate PyAudio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "def text_to_speech(text):\n",
    "    # Define the credentials file\n",
    "    credentials = service_account.Credentials.from_service_account_file('google_credential.json')\n",
    "\n",
    "    # Initialize the Text-to-Speech client\n",
    "    client = texttospeech.TextToSpeechClient(credentials=credentials)\n",
    "\n",
    "    # Set the text input to be synthesized\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "    # Build the voice request\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "    )\n",
    "\n",
    "    # Select the type of audio file you want returned\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    # Perform the text-to-speech request\n",
    "    response = client.synthesize_speech(\n",
    "        input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    # Use pydub to load the audio content\n",
    "    audio = AudioSegment.from_file(io.BytesIO(response.audio_content), format=\"mp3\")\n",
    "\n",
    "    # Play the audio\n",
    "    play_audio(audio)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"Now that the dinosaurs have left our house we can eat safely without being attacked!!!\"\n",
    "    startTime = time.time()\n",
    "    text_to_speech(text)\n",
    "    latency = time.time() - startTime\n",
    "    print(f\"latency:{latency} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071e2ab-17aa-4cda-a139-acb619eef01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def chatbot():\n",
    "  # Create a list to store all the messages for context\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "  ]\n",
    "\n",
    "  # Keep repeating the following\n",
    "  while True:\n",
    "    # Prompt user for input\n",
    "    message = input(\"User: \")\n",
    "\n",
    "    # Exit program if user inputs \"quit\"\n",
    "    if message.lower() == \"quit\":\n",
    "      break\n",
    "\n",
    "    # Add each new message to the list\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # Request gpt-3.5-turbo for chat completion\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=messages\n",
    "    )\n",
    "\n",
    "    # Print the response and add it to the messages list\n",
    "    chat_message = response['choices'][0]['message']['content']\n",
    "    print(f\"Bot: {chat_message}\")\n",
    "    messages.append({\"role\": \"assistant\", \"content\": chat_message})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  print(\"Start chatting with the bot (type 'quit' to stop)!\")\n",
    "  chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Voice Echo Enviroment",
   "language": "python",
   "name": "voiceechoenviroment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
